{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import nltk\n",
    "import re, string, unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "#from textblob import TextBlob\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('Datasets\\BL-Flickr-Images-Book.csv')\n",
    "data=pd.read_csv('D:\\\\R-Projects\\\\Amazon_Unlocked_Mobile.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews',\n",
       "       'Review Votes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413840, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "      <th>Negatively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>1</td>\n",
       "      <td>I already had a phone with problems... I know ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>The charging port was loose. I got that solder...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "5  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "6  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \\\n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0   \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0   \n",
       "2       5                                       Very pleased           0.0   \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0   \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0   \n",
       "5       1  I already had a phone with problems... I know ...           1.0   \n",
       "6       2  The charging port was loose. I got that solder...           0.0   \n",
       "\n",
       "   Positively Rated  Negatively Rated  \n",
       "0                 1                 5  \n",
       "1                 1                 5  \n",
       "2                 1                 5  \n",
       "3                 1                 5  \n",
       "4                 1                 5  \n",
       "5                 0                 4  \n",
       "6                 0                 4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's drop the neutral review which is always 3 so that we can remain with either negative or positive review\n",
    "data.dropna(inplace=True)\n",
    "data[data['Rating'] != 3]\n",
    "#Now we are defining the positive rating as those with greater than 3\n",
    "data['Positively Rated'] = np.where(data['Rating'] > 3, 1, 0)\n",
    "data['Negatively Rated'] = np.where(data['Rating'] < 3, 4, 5)\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6899487041440472"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Positively Rated'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.767888495072308"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Negatively Rated'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above mean is higher and it shows that reviews with higher mean are said to be more biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we want to do serious pre-processing\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    #words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "#Steemming and Lemmatization\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems, lemmas\n",
    "\n",
    "#stems, lemmas = stem_and_lemmatize(words)\n",
    "#print('Stemmed:\\n', stems)\n",
    "#print('\\nLemmatized:\\n', lemmas)\n",
    "\n",
    "\n",
    "# ---------------   Cleaning   ------------------\n",
    "def clean_text(text):\n",
    "    wording = nltk.word_tokenize(text)\n",
    "    words = normalize(wording)\n",
    "    string_text = ' '.join(words)\n",
    "    return string_text\n",
    "\n",
    "# ---------------   Sentiment   ------------------\n",
    "def get_text_sentiment(text):\n",
    "    # create TextBlob object of passed text \n",
    "    analysis = TextBlob(clean_text(text)) \n",
    "    # set sentiment \n",
    "    if analysis.sentiment.polarity > 0: \n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0: \n",
    "        return 'neutral'\n",
    "    else: \n",
    "        return 'negative'    \n",
    "    \n",
    "#---------------------- TextBlob Feature Extractions -----------------\n",
    "#Function to extract features from text\n",
    "def textBlob_feature_extraction(text): \n",
    "        blob = TextBlob(text)\n",
    "        return blob.noun_phrases\n",
    "    \n",
    "    \n",
    "#----------------------  extract Sentences  -------------------------    \n",
    "def sentances(text):\n",
    "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    return sent_detector.tokenize(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3820ecf39a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mreviews\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcleaned_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_text_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfeatures_Dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-358d3ac210ae>\u001b[0m in \u001b[0;36mget_text_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_text_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# create TextBlob object of passed text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0manalysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;31m# set sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "#-----------------  Text Cleaning & Sentiment Extraction --------------------\n",
    "cleaned_reviews =[]\n",
    "sentiment= []\n",
    "for reviews in data['Reviews']:\n",
    "    cleaned_reviews.append(clean_text(reviews))\n",
    "    sentiment.append(get_text_sentiment(reviews))\n",
    "    \n",
    "features_Dataset = pd.DataFrame()\n",
    "features_Dataset['Product Name'] = data['Product Name']\n",
    "features_Dataset['Reviews'] = data['Reviews']\n",
    "features_Dataset['Cleaned_Reviews'] = cleaned_reviews\n",
    "features_Dataset['Sentiment'] = sentiment\n",
    "\n",
    "\n",
    "# Extracting Features from each review using TextBlob & Spacy *\n",
    "    \n",
    "#--------------------- Text Blob -------------------------\n",
    "features = []\n",
    "for reviews in features_Dataset['Cleaned_Reviews']:\n",
    "    features.append(textBlob_feature_extraction(reviews))\n",
    "#adding Extracted features to dataset\n",
    "features_Dataset[\"TextBlob_Features\"] = features\n",
    "\n",
    "#--------------------- Spacy -----------------------------\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "feature_spacy = []\n",
    "for review in nlp.pipe(features_Dataset['Cleaned_Reviews']):\n",
    "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "    feature_spacy.append(','.join(chunks))\n",
    "\n",
    "features_Dataset['Spacy_features']= feature_spacy\n",
    "\n",
    "#---------------------------------------------------------\n",
    "features_Dataset.head()\n",
    "#https://www.kaggle.com/ahtxham/amazon-dataset-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many brands do we have in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(data['Brand Name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3675"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(data['Product Name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">count_nonzero</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AMM Global Enterprises</td>\n",
       "      <td>44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ARGOM TECH</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.82843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ASUS</td>\n",
       "      <td>2092</td>\n",
       "      <td>838.0</td>\n",
       "      <td>4.470085</td>\n",
       "      <td>1.790598</td>\n",
       "      <td>468</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1.08383</td>\n",
       "      <td>4.81999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ASUS Computers</td>\n",
       "      <td>2852</td>\n",
       "      <td>831.0</td>\n",
       "      <td>4.028249</td>\n",
       "      <td>1.173729</td>\n",
       "      <td>708</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1.3836</td>\n",
       "      <td>6.68461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ATT</td>\n",
       "      <td>160</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>44</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.79263</td>\n",
       "      <td>0.974028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Acer</td>\n",
       "      <td>68</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>22</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.71573</td>\n",
       "      <td>1.37778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aeku</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.65685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AeroAntenna</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Alcatel</td>\n",
       "      <td>5574</td>\n",
       "      <td>3174.0</td>\n",
       "      <td>4.039130</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1380</td>\n",
       "      <td>777.0</td>\n",
       "      <td>1.36885</td>\n",
       "      <td>8.09721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sum                   mean               \\\n",
       "                       Rating Review Votes    Rating Review Votes   \n",
       "AMM Global Enterprises     44          1.0  4.888889     0.111111   \n",
       "ARGOM TECH                  6          0.0  3.000000     0.000000   \n",
       "ASUS                     2092        838.0  4.470085     1.790598   \n",
       "ASUS Computers           2852        831.0  4.028249     1.173729   \n",
       "AT&T                        5          0.0  5.000000     0.000000   \n",
       "ATT                       160         25.0  3.636364     0.568182   \n",
       "Acer                       68         27.0  3.090909     1.227273   \n",
       "Aeku                       10          8.0  5.000000     4.000000   \n",
       "AeroAntenna                 5          0.0  5.000000     0.000000   \n",
       "Alcatel                  5574       3174.0  4.039130     2.300000   \n",
       "\n",
       "                       count_nonzero                    std               \n",
       "                              Rating Review Votes    Rating Review Votes  \n",
       "AMM Global Enterprises             9          1.0  0.333333     0.333333  \n",
       "ARGOM TECH                         2          0.0   2.82843            0  \n",
       "ASUS                             468        185.0   1.08383      4.81999  \n",
       "ASUS Computers                   708        228.0    1.3836      6.68461  \n",
       "AT&T                               1          0.0                         \n",
       "ATT                               44         17.0   1.79263     0.974028  \n",
       "Acer                              22         14.0   1.71573      1.37778  \n",
       "Aeku                               2          1.0         0      5.65685  \n",
       "AeroAntenna                        1          0.0                         \n",
       "Alcatel                         1380        777.0   1.36885      8.09721  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the summary of products\n",
    "pivot = pd.pivot_table(data,\n",
    "            values = ['Rating', 'Review Votes'],\n",
    "            index = ['Brand Name'], \n",
    "                       columns= [],\n",
    "                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n",
    "                       margins=True).fillna('')\n",
    "pivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"2\" halign=\"left\">count_nonzero</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>1278794</td>\n",
       "      <td>492982</td>\n",
       "      <td>3.824888</td>\n",
       "      <td>1.474515</td>\n",
       "      <td>334335</td>\n",
       "      <td>101271</td>\n",
       "      <td>1.5412</td>\n",
       "      <td>9.21733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Samsung</td>\n",
       "      <td>250452</td>\n",
       "      <td>96057</td>\n",
       "      <td>3.973032</td>\n",
       "      <td>1.523795</td>\n",
       "      <td>63038</td>\n",
       "      <td>18221</td>\n",
       "      <td>1.47913</td>\n",
       "      <td>9.95184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BLU</td>\n",
       "      <td>226085</td>\n",
       "      <td>54798</td>\n",
       "      <td>3.821069</td>\n",
       "      <td>0.926143</td>\n",
       "      <td>59168</td>\n",
       "      <td>15182</td>\n",
       "      <td>1.48947</td>\n",
       "      <td>5.45117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apple</td>\n",
       "      <td>220286</td>\n",
       "      <td>112211</td>\n",
       "      <td>3.926597</td>\n",
       "      <td>2.000160</td>\n",
       "      <td>56101</td>\n",
       "      <td>18355</td>\n",
       "      <td>1.57473</td>\n",
       "      <td>13.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LG</td>\n",
       "      <td>83266</td>\n",
       "      <td>22929</td>\n",
       "      <td>3.848493</td>\n",
       "      <td>1.059762</td>\n",
       "      <td>21636</td>\n",
       "      <td>5879</td>\n",
       "      <td>1.53039</td>\n",
       "      <td>5.09583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>61892</td>\n",
       "      <td>21114</td>\n",
       "      <td>3.750121</td>\n",
       "      <td>1.279326</td>\n",
       "      <td>16504</td>\n",
       "      <td>4058</td>\n",
       "      <td>1.59666</td>\n",
       "      <td>7.72454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Nokia</td>\n",
       "      <td>61833</td>\n",
       "      <td>25684</td>\n",
       "      <td>3.824879</td>\n",
       "      <td>1.588767</td>\n",
       "      <td>16166</td>\n",
       "      <td>5491</td>\n",
       "      <td>1.48911</td>\n",
       "      <td>7.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Motorola</td>\n",
       "      <td>49564</td>\n",
       "      <td>23107</td>\n",
       "      <td>3.811736</td>\n",
       "      <td>1.777051</td>\n",
       "      <td>13003</td>\n",
       "      <td>4392</td>\n",
       "      <td>1.52564</td>\n",
       "      <td>15.2721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HTC</td>\n",
       "      <td>42873</td>\n",
       "      <td>12777</td>\n",
       "      <td>3.474030</td>\n",
       "      <td>1.035329</td>\n",
       "      <td>12341</td>\n",
       "      <td>3170</td>\n",
       "      <td>1.65743</td>\n",
       "      <td>5.51806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CNPGD</td>\n",
       "      <td>38233</td>\n",
       "      <td>20151</td>\n",
       "      <td>3.107869</td>\n",
       "      <td>1.638026</td>\n",
       "      <td>12302</td>\n",
       "      <td>3502</td>\n",
       "      <td>1.61922</td>\n",
       "      <td>8.96474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OtterBox</td>\n",
       "      <td>34556</td>\n",
       "      <td>2268</td>\n",
       "      <td>4.385279</td>\n",
       "      <td>0.287817</td>\n",
       "      <td>7880</td>\n",
       "      <td>741</td>\n",
       "      <td>1.1622</td>\n",
       "      <td>2.62002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum                   mean              count_nonzero  \\\n",
       "             Rating Review Votes    Rating Review Votes        Rating   \n",
       "All         1278794       492982  3.824888     1.474515        334335   \n",
       "Samsung      250452        96057  3.973032     1.523795         63038   \n",
       "BLU          226085        54798  3.821069     0.926143         59168   \n",
       "Apple        220286       112211  3.926597     2.000160         56101   \n",
       "LG            83266        22929  3.848493     1.059762         21636   \n",
       "BlackBerry    61892        21114  3.750121     1.279326         16504   \n",
       "Nokia         61833        25684  3.824879     1.588767         16166   \n",
       "Motorola      49564        23107  3.811736     1.777051         13003   \n",
       "HTC           42873        12777  3.474030     1.035329         12341   \n",
       "CNPGD         38233        20151  3.107869     1.638026         12302   \n",
       "OtterBox      34556         2268  4.385279     0.287817          7880   \n",
       "\n",
       "                             std               \n",
       "           Review Votes   Rating Review Votes  \n",
       "All              101271   1.5412      9.21733  \n",
       "Samsung           18221  1.47913      9.95184  \n",
       "BLU               15182  1.48947      5.45117  \n",
       "Apple             18355  1.57473      13.2452  \n",
       "LG                 5879  1.53039      5.09583  \n",
       "BlackBerry         4058  1.59666      7.72454  \n",
       "Nokia              5491  1.48911        7.865  \n",
       "Motorola           4392  1.52564      15.2721  \n",
       "HTC                3170  1.65743      5.51806  \n",
       "CNPGD              3502  1.61922      8.96474  \n",
       "OtterBox            741   1.1622      2.62002  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can we get to know which brands are top performing?\n",
    "pivot = pd.pivot_table(data,\n",
    "            values = ['Rating', 'Review Votes'],\n",
    "            index =  ['Brand Name'],\n",
    "                       columns= [],\n",
    "                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n",
    "                       margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n",
    "top_10_brands = pivot.reindex().head(n=11)\n",
    "top_10_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped rows having NaN values\n",
    "data_df = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating              1.000000\n",
       "Positively Rated    0.925830\n",
       "Negatively Rated    0.915473\n",
       "Price               0.073948\n",
       "Review Votes       -0.046526\n",
       "Name: Rating, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What's the correlation between \n",
    "corr_matrix = data_df.corr()\n",
    "corr_matrix[\"Rating\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we can discover that Positively Rated brands have high corelation with Rating as compared to Negatively Rated.\n",
    "Price has minimal correlation while Review Votes lack any relationship with Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price               1.000000\n",
       "Rating              0.073948\n",
       "Positively Rated    0.073898\n",
       "Negatively Rated    0.054158\n",
       "Review Votes        0.022164\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = data_df.corr()\n",
    "corr_matrix[\"Price\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "      <th>Negatively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>380280</td>\n",
       "      <td>Samsung Note 2 I317 16GB Unlocked GSM 4G LTE Q...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>159.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Great phone. It worked as stated. The scratche...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290385</td>\n",
       "      <td>Pantech Breeze C520 Unlocked GSM Flip Phone</td>\n",
       "      <td>Pantech</td>\n",
       "      <td>13.95</td>\n",
       "      <td>4</td>\n",
       "      <td>thank you..i found a new phone just like my ol...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262150</td>\n",
       "      <td>Nokia 8600 Unlocked Phone (Black)</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>1169.10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100332</td>\n",
       "      <td>Blackberry Torch 2 9810 Unlocked Phone with 1....</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>77.49</td>\n",
       "      <td>5</td>\n",
       "      <td>excelete rpoducto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233627</td>\n",
       "      <td>LG Optimus G E970 16GB Unlocked GSM 4G LTE Qua...</td>\n",
       "      <td>LG</td>\n",
       "      <td>449.00</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product Name  Brand Name  \\\n",
       "380280  Samsung Note 2 I317 16GB Unlocked GSM 4G LTE Q...     Samsung   \n",
       "290385        Pantech Breeze C520 Unlocked GSM Flip Phone     Pantech   \n",
       "262150                  Nokia 8600 Unlocked Phone (Black)       Nokia   \n",
       "100332  Blackberry Torch 2 9810 Unlocked Phone with 1....  BlackBerry   \n",
       "233627  LG Optimus G E970 16GB Unlocked GSM 4G LTE Qua...          LG   \n",
       "\n",
       "          Price  Rating                                            Reviews  \\\n",
       "380280   159.95       5  Great phone. It worked as stated. The scratche...   \n",
       "290385    13.95       4  thank you..i found a new phone just like my ol...   \n",
       "262150  1169.10       1                                               Fake   \n",
       "100332    77.49       5                                  excelete rpoducto   \n",
       "233627   449.00       5                                          Excellent   \n",
       "\n",
       "        Review Votes  Positively Rated  Negatively Rated  \n",
       "380280           0.0                 1                 5  \n",
       "290385           1.0                 1                 5  \n",
       "262150           1.0                 0                 4  \n",
       "100332           0.0                 1                 5  \n",
       "233627           0.0                 1                 5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The shuffle library works like indexing\n",
    "from sklearn.utils import shuffle\n",
    "data_df = shuffle(data) #Shuffle Data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "      <th>Negatively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Samsung Note 2 I317 16GB Unlocked GSM 4G LTE Q...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>159.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Great phone. It worked as stated. The scratche...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pantech Breeze C520 Unlocked GSM Flip Phone</td>\n",
       "      <td>Pantech</td>\n",
       "      <td>13.95</td>\n",
       "      <td>4</td>\n",
       "      <td>thank you..i found a new phone just like my ol...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Nokia 8600 Unlocked Phone (Black)</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>1169.10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Blackberry Torch 2 9810 Unlocked Phone with 1....</td>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>77.49</td>\n",
       "      <td>5</td>\n",
       "      <td>excelete rpoducto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LG Optimus G E970 16GB Unlocked GSM 4G LTE Qua...</td>\n",
       "      <td>LG</td>\n",
       "      <td>449.00</td>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name  Brand Name    Price  \\\n",
       "0  Samsung Note 2 I317 16GB Unlocked GSM 4G LTE Q...     Samsung   159.95   \n",
       "1        Pantech Breeze C520 Unlocked GSM Flip Phone     Pantech    13.95   \n",
       "2                  Nokia 8600 Unlocked Phone (Black)       Nokia  1169.10   \n",
       "3  Blackberry Torch 2 9810 Unlocked Phone with 1....  BlackBerry    77.49   \n",
       "4  LG Optimus G E970 16GB Unlocked GSM 4G LTE Qua...          LG   449.00   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \\\n",
       "0       5  Great phone. It worked as stated. The scratche...           0.0   \n",
       "1       4  thank you..i found a new phone just like my ol...           1.0   \n",
       "2       1                                               Fake           1.0   \n",
       "3       5                                  excelete rpoducto           0.0   \n",
       "4       5                                          Excellent           0.0   \n",
       "\n",
       "   Positively Rated  Negatively Rated  \n",
       "0                 1                 5  \n",
       "1                 1                 5  \n",
       "2                 0                 4  \n",
       "3                 1                 5  \n",
       "4                 1                 5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can then decide to reset our index by writing the function below\n",
    "#reset_index\n",
    "data = data_df.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's advice the Apple Company on their phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "      <th>Negatively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Apple iPhone 3GS A1303 16GB GSM Unlocked Smart...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>39.00</td>\n",
       "      <td>5</td>\n",
       "      <td>Excelente</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Apple iPhone 5s T-Mobile Cellphone, 16GB, Spac...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>168.77</td>\n",
       "      <td>1</td>\n",
       "      <td>I unlock this phone on the site [...] for use ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Apple iPhone 6S Plus Unlocked Smartphone, 32 G...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>749.99</td>\n",
       "      <td>5</td>\n",
       "      <td>AWESOME!!!! I haven't figured out the technolo...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Apple iPhone 5c 16GB (Yellow) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>248.00</td>\n",
       "      <td>4</td>\n",
       "      <td>it has a glitch that drops wifi, and you can't...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Apple iPhone 5s 32GB (Gold) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>54.34</td>\n",
       "      <td>5</td>\n",
       "      <td>grate phone fore the price. got it for gift fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Apple iPhone 7 Unlocked Phone 128 GB - US Vers...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>829.95</td>\n",
       "      <td>1</td>\n",
       "      <td>This is fake phone not the original iPhone 7 I...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Apple iPhone 6s 64 GB International Warranty U...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>689.95</td>\n",
       "      <td>5</td>\n",
       "      <td>Good condition as posted. Very pleased!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Apple iPhone SE Unlocked Phone - 64 GB Retail ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>500.00</td>\n",
       "      <td>5</td>\n",
       "      <td>I got this phone for my wife. It is a great up...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product Name Brand Name   Price  \\\n",
       "13  Apple iPhone 3GS A1303 16GB GSM Unlocked Smart...      Apple   39.00   \n",
       "14  Apple iPhone 5s T-Mobile Cellphone, 16GB, Spac...      Apple  168.77   \n",
       "21  Apple iPhone 6S Plus Unlocked Smartphone, 32 G...      Apple  749.99   \n",
       "31               Apple iPhone 5c 16GB (Yellow) - AT&T      Apple  248.00   \n",
       "33                 Apple iPhone 5s 32GB (Gold) - AT&T      Apple   54.34   \n",
       "37  Apple iPhone 7 Unlocked Phone 128 GB - US Vers...      Apple  829.95   \n",
       "38  Apple iPhone 6s 64 GB International Warranty U...      Apple  689.95   \n",
       "41  Apple iPhone SE Unlocked Phone - 64 GB Retail ...      Apple  500.00   \n",
       "\n",
       "    Rating                                            Reviews  Review Votes  \\\n",
       "13       5                                          Excelente           0.0   \n",
       "14       1  I unlock this phone on the site [...] for use ...           1.0   \n",
       "21       5  AWESOME!!!! I haven't figured out the technolo...           3.0   \n",
       "31       4  it has a glitch that drops wifi, and you can't...           0.0   \n",
       "33       5  grate phone fore the price. got it for gift fo...           0.0   \n",
       "37       1  This is fake phone not the original iPhone 7 I...           2.0   \n",
       "38       5            Good condition as posted. Very pleased!           0.0   \n",
       "41       5  I got this phone for my wife. It is a great up...           0.0   \n",
       "\n",
       "    Positively Rated  Negatively Rated  \n",
       "13                 1                 5  \n",
       "14                 0                 4  \n",
       "21                 1                 5  \n",
       "31                 1                 5  \n",
       "33                 1                 5  \n",
       "37                 0                 4  \n",
       "38                 1                 5  \n",
       "41                 1                 5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The data of apple phones in the dataset\n",
    "data_apple = data.loc[data['Brand Name'].isin(['Apple'])]\n",
    "pivot = pd.pivot_table(data_apple,\n",
    "        values = ['Rating', 'Review Votes'],\n",
    "        index =  ['Product Name'],\n",
    "                   columns= [],\n",
    "                   aggfunc=[np.sum, np.mean, np.count_nonzero], \n",
    "                   margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n",
    "topmost_prods = pivot.reindex().head(n=30)\n",
    "topmost_prods = topmost_prods.reset_index()\n",
    "topmost_prods\n",
    "data_apple.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling starts here with Bag-of-Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Reviews'], data['Positively Rated'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '85f',\n",
       " 'appworld',\n",
       " 'bothare',\n",
       " 'coke',\n",
       " 'decidir',\n",
       " 'eggs',\n",
       " 'fingerprint3',\n",
       " 'h860',\n",
       " 'intelligible',\n",
       " 'locals',\n",
       " 'murtadha',\n",
       " 'owner',\n",
       " 'proble3m',\n",
       " 'reparaciones',\n",
       " 'sharp',\n",
       " 'stunt',\n",
       " 'tracy',\n",
       " 'vqlhccjh434']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56541"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250751x56541 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6831683 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['stylist' 'false' 'worst' 'unsatisfied' 'horribly' 'raymond' 'mony'\n",
      " 'worthless' 'unusable' 'saler']\n",
      "\n",
      "Largest Coefs: \n",
      "['excelent' 'excelente' 'perfecto' 'exelente' 'excellent' 'awsome'\n",
      " 'loving' 'superb' 'eight' 'exellent']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df = 5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Tfidf: \n",
      "['junction' 'overreacted' 'override' 'overriding' 'overrode' 'overruled'\n",
      " 'overs' 'oversaes' 'oversampling' 'oversaturated']\n",
      "\n",
      "Largest Tfidf: \n",
      "['the' 'to' 'and' 'it' 'you' 'phone' 'is' 'of' 'on' 'this']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coef: \n",
      "['stylist' 'false' 'worst' 'unsatisfied' 'horribly' 'raymond' 'mony'\n",
      " 'worthless' 'unusable' 'saler']\n",
      "\n",
      "Largest coef: \n",
      "['excelent' 'excelente' 'perfecto' 'exelente' 'excellent' 'awsome'\n",
      " 'loving' 'superb' 'eight' 'exellent']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest coef: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest coef: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "\n",
    "print(model.predict(vect.transform(['Not an issue, phone is working', \n",
    "                                   'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217247"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fe7f5c7c4722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:10]))\n",
    "print('Largest Coef: \\n{}\\n'.format(feature_names[sorted_coef_index][:-11:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                   'an issue, phone is not working'])))\n",
    "#https://github.com/susanli2016/NLP-with-Python/blob/master/Amazon%20Reviews.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns using the `.apply` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_characters = ['[', ',', '-']\n",
    "\n",
    "def clean_dates(item):\n",
    "    dop= str(item.loc['Date of Publication'])\n",
    "    \n",
    "    if dop == 'nan' or dop[0] == '[':\n",
    "        return np.NaN\n",
    "    \n",
    "    for character in unwanted_characters:\n",
    "        if character in dop:\n",
    "            character_index = dop.find(character)\n",
    "            dop = dop[:character_index]\n",
    "    \n",
    "    return dop\n",
    "\n",
    "df['Date of Publication'] = df.apply(clean_dates, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate way of cleaning Date of Publication\n",
    "#run cell to see output\n",
    "unwanted_characters = ['[', ',', '-']\n",
    "\n",
    "def clean_dates(dop):\n",
    "    dop = str(dop)\n",
    "    if dop.startswith('[') or dop == 'nan':\n",
    "        return 'NaN'\n",
    "    for character in unwanted_characters:\n",
    "        if character in dop:\n",
    "            character_index = dop.find(character)\n",
    "            dop = dop[:character_index]\n",
    "    return dop\n",
    "\n",
    "df['Date of Publication'] = df['Date of Publication'].apply(clean_dates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_author_names(author):\n",
    "    \n",
    "    author = str(author)\n",
    "    \n",
    "    if author == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    author = author.split(',')\n",
    "\n",
    "    if len(author) == 1:\n",
    "        name = filter(lambda x: x.isalpha(), author[0])\n",
    "        return reduce(lambda x, y: x + y, name)\n",
    "    \n",
    "    last_name, first_name = author[0], author[1]\n",
    "\n",
    "    first_name = first_name[:first_name.find('-')] if '-' in first_name else first_name\n",
    "    \n",
    "    if first_name.endswith(('.', '.|')):\n",
    "        parts = first_name.split('.')\n",
    "        \n",
    "        if len(parts) > 1:\n",
    "            first_occurence = first_name.find('.')\n",
    "            final_occurence = first_name.find('.', first_occurence + 1)\n",
    "            first_name = first_name[:final_occurence]\n",
    "        else:\n",
    "            first_name = first_name[:first_name.find('.')]\n",
    "    \n",
    "    last_name = last_name.capitalize()\n",
    "    \n",
    "    return f'{first_name} {last_name}'\n",
    "\n",
    "\n",
    "df['Author'] = df['Author'].apply(clean_author_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(title):\n",
    "    \n",
    "    if title == 'nan':\n",
    "        return 'NaN'\n",
    "    \n",
    "    if title[0] == '[':\n",
    "        title = title[1: title.find(']')]\n",
    "        \n",
    "    if 'by' in title:\n",
    "        title = title[:title.find('by')]\n",
    "    elif 'By' in title:\n",
    "        title = title[:title.find('By')]\n",
    "        \n",
    "    if '[' in title:\n",
    "        title = title[:title.find('[')]\n",
    "\n",
    "    title = title[:-2]\n",
    "        \n",
    "    title = list(map(str.capitalize, title.split()))\n",
    "    return ' '.join(title)\n",
    "    \n",
    "df['Title'] = df['Title'].apply(clean_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `.str` methods to clean columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4157862 and 4159587\n",
    "df.loc[4159587]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = df['Place of Publication']\n",
    "df['Place of Publication'] = np.where(pub.str.contains('London'), 'London',\n",
    "    np.where(pub.str.contains('Oxford'), 'Oxford',\n",
    "        np.where(pub.eq('Newcastle upon Tyne'),\n",
    "            'Newcastle-upon-Tyne', df['Place of Publication'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!more Datasets\\\\university_towns.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_towns = []\n",
    "\n",
    "with open('Datasets\\\\university_towns.txt', 'r') as file:\n",
    "    items = file.readlines()\n",
    "    states = list(filter(lambda x: '[edit]' in x, items))\n",
    "    \n",
    "    for index, state in enumerate(states):\n",
    "        start = items.index(state) + 1\n",
    "        if index == 49: #since 50 states\n",
    "            end = len(items)\n",
    "        else:\n",
    "            end = items.index(states[index + 1])\n",
    "            \n",
    "        pairs = map(lambda x: [state, x], items[start:end])\n",
    "        university_towns.extend(pairs)\n",
    "        \n",
    "towns_df = pd.DataFrame(university_towns, columns = ['State', 'RegionName'])\n",
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(item):\n",
    "    if '(' in item:\n",
    "        return item[:item.find('(') - 1]\n",
    "    \n",
    "    if '[' in item:\n",
    "        return item[:item.find('[')]\n",
    "    \n",
    "\n",
    "towns_df =  towns_df.applymap(clean_up)\n",
    "towns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns and skipping rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('Datasets\\olympics.csv')\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df = pd.read_csv('Datasets\\olympics.csv', skiprows = 1, header = 0)\n",
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  {'Unnamed: 0': 'Country',\n",
    "              '? Summer': 'Summer Olympics',\n",
    "              '01 !': 'Gold',\n",
    "              '02 !': 'Silver',\n",
    "              '03 !': 'Bronze',\n",
    "              '? Winter': 'Winter Olympics',\n",
    "              '01 !.1': 'Gold.1',\n",
    "              '02 !.1': 'Silver.1',\n",
    "              '03 !.1': 'Bronze.1',\n",
    "              '? Games': '# Games', \n",
    "              '01 !.2': 'Gold.2',\n",
    "              '02 !.2': 'Silver.2',\n",
    "              '03 !.2': 'Bronze.2'}\n",
    "\n",
    "olympics_df.rename(columns = new_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
